{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517cd648",
   "metadata": {},
   "source": [
    "# Traffic Flow Analysis Using CCTV Footage\n",
    "\n",
    "## Comprehensive Demo: Object Detection, Vehicle Classification, and Congestion Analysis\n",
    "\n",
    "This notebook demonstrates a complete traffic flow analysis system that:\n",
    "- **Detects vehicles** in CCTV footage using YOLO\n",
    "- **Classifies vehicle types** (car, bike, bus, truck)\n",
    "- **Tracks vehicle movement** across frames\n",
    "- **Estimates congestion levels** and traffic patterns\n",
    "- **Provides analytics** for smart city applications\n",
    "\n",
    "**Key Technologies:**\n",
    "- Computer Vision: OpenCV, YOLO, Deep Learning\n",
    "- Data Science: Pandas, NumPy, Statistical Modeling\n",
    "- Visualization: Matplotlib, Seaborn, Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ba369",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import OpenCV, YOLO/detectron2, NumPy, pandas, matplotlib, and other necessary libraries for computer vision and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a31e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for computer vision and data processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Deep learning and object detection\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Additional utilities\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project path to system path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import our custom modules\n",
    "from src.detection.vehicle_detector import VehicleDetector\n",
    "from src.tracking.vehicle_tracker import VehicleTracker\n",
    "from src.classification.vehicle_classifier import VehicleClassifier\n",
    "from src.analytics.traffic_analyzer import TrafficAnalyzer\n",
    "from src.visualization.traffic_visualizer import TrafficVisualizer\n",
    "from src.utils.helpers import *\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd5f5d",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Video Data\n",
    "\n",
    "Load CCTV video files, extract frames, and apply preprocessing techniques like resizing and noise reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c74750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for video processing\n",
    "VIDEO_PATH = \"../data/videos/sample_traffic.mp4\"  # Update with your video path\n",
    "SAMPLE_FRAMES = 5  # Number of frames to display for preview\n",
    "\n",
    "def load_and_preview_video(video_path: str, max_frames: int = 5):\n",
    "    \"\"\"Load video and show sample frames\"\"\"\n",
    "\n",
    "    # Check if video file exists (for demo, we'll create a placeholder)\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"âš ï¸ Video file not found at {video_path}\")\n",
    "        print(\"ðŸ“ For this demo, we'll simulate video processing\")\n",
    "        print(\"   In a real scenario, place your CCTV footage in the data/videos/ directory\")\n",
    "        return None\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Error opening video file\")\n",
    "        return None\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = frame_count / fps\n",
    "\n",
    "    print(f\"ðŸ“¹ Video Properties:\")\n",
    "    print(f\"   Resolution: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps:.2f}\")\n",
    "    print(f\"   Total Frames: {frame_count}\")\n",
    "    print(f\"   Duration: {duration:.2f} seconds\")\n",
    "\n",
    "    # Extract sample frames\n",
    "    frames = []\n",
    "    frame_indices = np.linspace(0, frame_count-1, max_frames, dtype=int)\n",
    "\n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Display sample frames\n",
    "    if frames:\n",
    "        fig, axes = plt.subplots(1, len(frames), figsize=(15, 3))\n",
    "        if len(frames) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, (frame, ax) in enumerate(zip(frames, axes)):\n",
    "            # Convert BGR to RGB for matplotlib\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(frame_rgb)\n",
    "            ax.set_title(f'Frame {frame_indices[i]}')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.suptitle('Sample Frames from Traffic Video')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return frames\n",
    "\n",
    "def preprocess_frame(frame: np.ndarray, target_size: Tuple[int, int] = None) -> np.ndarray:\n",
    "    \"\"\"Apply preprocessing to frame\"\"\"\n",
    "    processed = frame.copy()\n",
    "\n",
    "    # Resize if target size specified\n",
    "    if target_size:\n",
    "        processed = cv2.resize(processed, target_size)\n",
    "\n",
    "    # Apply slight noise reduction\n",
    "    processed = cv2.bilateralFilter(processed, 9, 75, 75)\n",
    "\n",
    "    # Enhance contrast slightly\n",
    "    processed = cv2.convertScaleAbs(processed, alpha=1.1, beta=10)\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Load and preview video\n",
    "print(\"ðŸŽ¬ Loading and previewing video data...\")\n",
    "sample_frames = load_and_preview_video(VIDEO_PATH, SAMPLE_FRAMES)\n",
    "\n",
    "# Demonstrate preprocessing\n",
    "if sample_frames:\n",
    "    print(\"\\nðŸ”„ Demonstrating frame preprocessing...\")\n",
    "\n",
    "    original = sample_frames[0]\n",
    "    processed = preprocess_frame(original, target_size=(640, 480))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Original Frame')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(cv2.cvtColor(processed, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title('Preprocessed Frame')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Create synthetic demo data for visualization\n",
    "    print(\"\\nðŸŽ¨ Creating synthetic demo frame...\")\n",
    "\n",
    "    # Create a synthetic traffic scene\n",
    "    demo_frame = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    demo_frame[:] = [50, 50, 50]  # Dark gray background\n",
    "\n",
    "    # Draw road\n",
    "    cv2.rectangle(demo_frame, (0, 200), (640, 280), (60, 60, 60), -1)\n",
    "\n",
    "    # Draw lane markings\n",
    "    for x in range(0, 640, 40):\n",
    "        cv2.rectangle(demo_frame, (x, 235), (x+20, 245), (255, 255, 255), -1)\n",
    "\n",
    "    # Draw some \"vehicles\" as rectangles\n",
    "    vehicles = [\n",
    "        (100, 210, 160, 270, (0, 0, 255)),   # Red car\n",
    "        (250, 215, 300, 265, (255, 0, 0)),   # Blue car\n",
    "        (400, 205, 480, 275, (0, 255, 255)), # Yellow bus\n",
    "    ]\n",
    "\n",
    "    for x1, y1, x2, y2, color in vehicles:\n",
    "        cv2.rectangle(demo_frame, (x1, y1), (x2, y2), color, -1)\n",
    "        cv2.rectangle(demo_frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(demo_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Synthetic Demo Traffic Scene')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    sample_frames = [demo_frame]\n",
    "\n",
    "print(\"âœ… Video data loading and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ba817",
   "metadata": {},
   "source": [
    "## 3. Setup Object Detection Model\n",
    "\n",
    "Initialize a pre-trained object detection model (YOLO or similar) and configure it for vehicle detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO model for vehicle detection\n",
    "print(\"ðŸ¤– Setting up object detection model...\")\n",
    "\n",
    "try:\n",
    "    # Load YOLOv8 model (you can also use YOLOv5 or other versions)\n",
    "    model = YOLO('yolov8n.pt')  # nano version for faster inference\n",
    "    print(\"âœ… YOLOv8 model loaded successfully!\")\n",
    "\n",
    "    # Display model information\n",
    "    print(f\"   Model classes: {len(model.names)} classes\")\n",
    "    print(f\"   Vehicle-related classes: {[name for id, name in model.names.items() if name in ['car', 'motorcycle', 'bus', 'truck', 'bicycle']]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not load YOLOv8 model: {e}\")\n",
    "    print(\"   Using mock detection for demo purposes\")\n",
    "    model = None\n",
    "\n",
    "# Vehicle class mapping from COCO dataset\n",
    "VEHICLE_CLASSES = {\n",
    "    'car': 2,\n",
    "    'motorcycle': 3,\n",
    "    'bus': 5,\n",
    "    'truck': 7,\n",
    "    'bicycle': 1\n",
    "}\n",
    "\n",
    "# Configuration for detection\n",
    "DETECTION_CONFIG = {\n",
    "    'confidence_threshold': 0.5,\n",
    "    'nms_threshold': 0.4,\n",
    "    'input_size': (640, 640)\n",
    "}\n",
    "\n",
    "def detect_vehicles_demo(frame, model=None, show_all_detections=False):\n",
    "    \"\"\"Demo function for vehicle detection\"\"\"\n",
    "\n",
    "    if model is not None:\n",
    "        # Real YOLO detection\n",
    "        results = model(frame, conf=DETECTION_CONFIG['confidence_threshold'],\n",
    "                       iou=DETECTION_CONFIG['nms_threshold'])\n",
    "\n",
    "        detections = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    confidence = box.conf[0].cpu().numpy()\n",
    "                    class_id = int(box.cls[0].cpu().numpy())\n",
    "                    class_name = model.names[class_id]\n",
    "\n",
    "                    # Filter for vehicles or show all if requested\n",
    "                    if show_all_detections or class_id in VEHICLE_CLASSES.values():\n",
    "                        detection = {\n",
    "                            'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                            'confidence': float(confidence),\n",
    "                            'class': class_name,\n",
    "                            'class_id': class_id,\n",
    "                            'is_vehicle': class_id in VEHICLE_CLASSES.values()\n",
    "                        }\n",
    "                        detections.append(detection)\n",
    "\n",
    "        return detections\n",
    "\n",
    "    else:\n",
    "        # Mock detection for demo\n",
    "        mock_detections = [\n",
    "            {'bbox': [100, 210, 160, 270], 'confidence': 0.85, 'class': 'car', 'class_id': 2, 'is_vehicle': True},\n",
    "            {'bbox': [250, 215, 300, 265], 'confidence': 0.92, 'class': 'car', 'class_id': 2, 'is_vehicle': True},\n",
    "            {'bbox': [400, 205, 480, 275], 'confidence': 0.78, 'class': 'bus', 'class_id': 5, 'is_vehicle': True},\n",
    "        ]\n",
    "        return mock_detections\n",
    "\n",
    "def visualize_detections(frame, detections):\n",
    "    \"\"\"Visualize detection results on frame\"\"\"\n",
    "    vis_frame = frame.copy()\n",
    "\n",
    "    colors = {\n",
    "        'car': (0, 255, 0),      # Green\n",
    "        'motorcycle': (255, 0, 0), # Blue\n",
    "        'bus': (0, 0, 255),      # Red\n",
    "        'truck': (255, 255, 0),  # Cyan\n",
    "        'bicycle': (255, 0, 255), # Magenta\n",
    "    }\n",
    "\n",
    "    for detection in detections:\n",
    "        bbox = detection['bbox']\n",
    "        class_name = detection['class']\n",
    "        confidence = detection['confidence']\n",
    "\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        color = colors.get(class_name, (255, 255, 255))\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Draw label\n",
    "        label = f\"{class_name}: {confidence:.2f}\"\n",
    "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "        cv2.rectangle(vis_frame, (x1, y1 - label_size[1] - 10),\n",
    "                     (x1 + label_size[0], y1), color, -1)\n",
    "        cv2.putText(vis_frame, label, (x1, y1 - 5),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "    return vis_frame\n",
    "\n",
    "# Test detection on sample frame\n",
    "if sample_frames:\n",
    "    print(\"\\nðŸ” Testing vehicle detection...\")\n",
    "\n",
    "    test_frame = sample_frames[0]\n",
    "    detections = detect_vehicles_demo(test_frame, model)\n",
    "\n",
    "    print(f\"   Detected {len(detections)} vehicles:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        print(f\"     {i+1}. {det['class']} (confidence: {det['confidence']:.2f})\")\n",
    "\n",
    "    # Visualize results\n",
    "    vis_frame = visualize_detections(test_frame, detections)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(test_frame, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Original Frame')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title(f'Vehicle Detection Results ({len(detections)} vehicles)')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Detection statistics\n",
    "    vehicle_counts = {}\n",
    "    for det in detections:\n",
    "        vehicle_type = det['class']\n",
    "        vehicle_counts[vehicle_type] = vehicle_counts.get(vehicle_type, 0) + 1\n",
    "\n",
    "    if vehicle_counts:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(vehicle_counts.keys(), vehicle_counts.values(), color=['skyblue', 'orange', 'lightgreen', 'pink', 'yellow'])\n",
    "        plt.title('Vehicle Detection Summary')\n",
    "        plt.xlabel('Vehicle Type')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"âœ… Object detection model setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce528b2",
   "metadata": {},
   "source": [
    "## 4. Implement Vehicle Detection and Classification\n",
    "\n",
    "Detect vehicles in video frames and classify them into categories (car, bike, bus, truck) using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced vehicle detection and classification system\n",
    "print(\"ðŸŽ¯ Implementing enhanced vehicle detection and classification...\")\n",
    "\n",
    "class EnhancedVehicleClassifier:\n",
    "    \"\"\"Enhanced vehicle classifier with feature extraction\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vehicle_features = {}\n",
    "\n",
    "    def extract_features(self, image_crop, bbox):\n",
    "        \"\"\"Extract features from vehicle crop\"\"\"\n",
    "        if image_crop.size == 0:\n",
    "            return np.zeros(10)  # Return zero features for empty crop\n",
    "\n",
    "        # Basic geometric features\n",
    "        height, width = image_crop.shape[:2] if len(image_crop.shape) >= 2 else (1, 1)\n",
    "        aspect_ratio = width / height if height > 0 else 0\n",
    "        area = width * height\n",
    "\n",
    "        # Color features (simplified)\n",
    "        if len(image_crop.shape) == 3:\n",
    "            mean_colors = np.mean(image_crop.reshape(-1, 3), axis=0)\n",
    "        else:\n",
    "            mean_colors = [0, 0, 0]\n",
    "\n",
    "        # Texture features (simplified)\n",
    "        gray = cv2.cvtColor(image_crop, cv2.COLOR_BGR2GRAY) if len(image_crop.shape) == 3 else image_crop\n",
    "        if gray.size > 0:\n",
    "            gradient = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "            texture_measure = np.var(gradient)\n",
    "        else:\n",
    "            texture_measure = 0\n",
    "\n",
    "        features = np.array([\n",
    "            width, height, aspect_ratio, area,\n",
    "            mean_colors[0], mean_colors[1], mean_colors[2],\n",
    "            texture_measure,\n",
    "            np.std(gray) if gray.size > 0 else 0,\n",
    "            np.mean(gray) if gray.size > 0 else 0\n",
    "        ])\n",
    "\n",
    "        return features\n",
    "\n",
    "    def classify_vehicle_enhanced(self, image_crop, bbox, base_class):\n",
    "        \"\"\"Enhanced classification using feature analysis\"\"\"\n",
    "        features = self.extract_features(image_crop, bbox)\n",
    "\n",
    "        # Rule-based enhancement\n",
    "        width, height, aspect_ratio, area = features[:4]\n",
    "\n",
    "        # Refine classification based on features\n",
    "        if base_class == 'car':\n",
    "            if aspect_ratio > 2.0 and area > 8000:\n",
    "                return 'bus', 0.8\n",
    "            elif aspect_ratio < 1.2 and area > 6000:\n",
    "                return 'truck', 0.75\n",
    "        elif base_class == 'motorcycle':\n",
    "            if area > 5000:  # Too large for motorcycle\n",
    "                return 'car', 0.7\n",
    "\n",
    "        return base_class, 0.9  # Return original with high confidence\n",
    "\n",
    "# Initialize enhanced classifier\n",
    "enhanced_classifier = EnhancedVehicleClassifier()\n",
    "\n",
    "def process_frame_with_classification(frame, model=None):\n",
    "    \"\"\"Process frame with detection and enhanced classification\"\"\"\n",
    "    detections = detect_vehicles_demo(frame, model)\n",
    "\n",
    "    enhanced_detections = []\n",
    "    for detection in detections:\n",
    "        bbox = detection['bbox']\n",
    "        x1, y1, x2, y2 = bbox\n",
    "\n",
    "        # Extract vehicle crop\n",
    "        vehicle_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Enhanced classification\n",
    "        enhanced_class, confidence = enhanced_classifier.classify_vehicle_enhanced(\n",
    "            vehicle_crop, bbox, detection['class']\n",
    "        )\n",
    "\n",
    "        enhanced_detection = detection.copy()\n",
    "        enhanced_detection['enhanced_class'] = enhanced_class\n",
    "        enhanced_detection['enhanced_confidence'] = confidence\n",
    "\n",
    "        enhanced_detections.append(enhanced_detection)\n",
    "\n",
    "    return enhanced_detections\n",
    "\n",
    "# Demonstrate enhanced classification\n",
    "if sample_frames:\n",
    "    print(\"\\nðŸ§  Demonstrating enhanced vehicle classification...\")\n",
    "\n",
    "    enhanced_detections = process_frame_with_classification(sample_frames[0], model)\n",
    "\n",
    "    # Create visualization comparing original vs enhanced classification\n",
    "    fig, axes = plt.subplots(2, len(enhanced_detections), figsize=(15, 8))\n",
    "    if len(enhanced_detections) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    for i, detection in enumerate(enhanced_detections):\n",
    "        bbox = detection['bbox']\n",
    "        x1, y1, x2, y2 = bbox\n",
    "\n",
    "        # Extract vehicle crop\n",
    "        vehicle_crop = sample_frames[0][y1:y2, x1:x2]\n",
    "        if vehicle_crop.size > 0:\n",
    "            vehicle_crop_rgb = cv2.cvtColor(vehicle_crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Original classification\n",
    "            axes[0, i].imshow(vehicle_crop_rgb)\n",
    "            axes[0, i].set_title(f\"Original: {detection['class']}\\\\n({detection['confidence']:.2f})\")\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            # Enhanced classification\n",
    "            axes[1, i].imshow(vehicle_crop_rgb)\n",
    "            axes[1, i].set_title(f\"Enhanced: {detection['enhanced_class']}\\\\n({detection['enhanced_confidence']:.2f})\")\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "    plt.suptitle('Vehicle Classification Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Classification summary\n",
    "    print(\"\\\\nðŸ“Š Classification Results:\")\n",
    "    for i, detection in enumerate(enhanced_detections):\n",
    "        print(f\"   Vehicle {i+1}:\")\n",
    "        print(f\"     Original: {detection['class']} ({detection['confidence']:.2f})\")\n",
    "        print(f\"     Enhanced: {detection['enhanced_class']} ({detection['enhanced_confidence']:.2f})\")\n",
    "\n",
    "        # Feature analysis\n",
    "        bbox = detection['bbox']\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        vehicle_crop = sample_frames[0][y1:y2, x1:x2]\n",
    "        features = enhanced_classifier.extract_features(vehicle_crop, bbox)\n",
    "\n",
    "        print(f\"     Features: W={features[0]:.0f}, H={features[1]:.0f}, AR={features[2]:.2f}\")\n",
    "\n",
    "print(\"\\\\nâœ… Enhanced vehicle detection and classification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61836a3f",
   "metadata": {},
   "source": [
    "## 5. Track Vehicle Movement\n",
    "\n",
    "Implement object tracking algorithms to follow vehicles across frames and maintain consistent IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f551b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle tracking implementation\n",
    "print(\"ðŸŽ¯ Implementing vehicle tracking system...\")\n",
    "\n",
    "class SimpleVehicleTracker:\n",
    "    \"\"\"Simple centroid-based vehicle tracker for demo\"\"\"\n",
    "\n",
    "    def __init__(self, max_disappeared=10, max_distance=100):\n",
    "        self.next_object_id = 0\n",
    "        self.objects = {}\n",
    "        self.disappeared = {}\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_distance = max_distance\n",
    "\n",
    "    def register(self, centroid, detection):\n",
    "        \"\"\"Register new object\"\"\"\n",
    "        self.objects[self.next_object_id] = {\n",
    "            'centroid': centroid,\n",
    "            'detection': detection,\n",
    "            'trajectory': [centroid],\n",
    "            'frame_count': 1\n",
    "        }\n",
    "        self.disappeared[self.next_object_id] = 0\n",
    "        object_id = self.next_object_id\n",
    "        self.next_object_id += 1\n",
    "        return object_id\n",
    "\n",
    "    def deregister(self, object_id):\n",
    "        \"\"\"Remove object\"\"\"\n",
    "        del self.objects[object_id]\n",
    "        del self.disappeared[object_id]\n",
    "\n",
    "    def update(self, detections):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        if len(detections) == 0:\n",
    "            # Mark all objects as disappeared\n",
    "            for object_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            return self.objects\n",
    "\n",
    "        # Get centroids from detections\n",
    "        input_centroids = []\n",
    "        for detection in detections:\n",
    "            bbox = detection['bbox']\n",
    "            cx = (bbox[0] + bbox[2]) // 2\n",
    "            cy = (bbox[1] + bbox[3]) // 2\n",
    "            input_centroids.append((cx, cy))\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            # Register all new objects\n",
    "            for i, centroid in enumerate(input_centroids):\n",
    "                self.register(centroid, detections[i])\n",
    "        else:\n",
    "            # Match existing objects with new detections\n",
    "            object_centroids = [obj['centroid'] for obj in self.objects.values()]\n",
    "            object_ids = list(self.objects.keys())\n",
    "\n",
    "            # Compute distance matrix\n",
    "            distances = np.linalg.norm(\n",
    "                np.array(object_centroids)[:, np.newaxis] - np.array(input_centroids),\n",
    "                axis=2\n",
    "            )\n",
    "\n",
    "            # Find minimum distance associations\n",
    "            rows = distances.min(axis=1).argsort()\n",
    "            cols = distances.argmin(axis=1)[rows]\n",
    "\n",
    "            used_row_indices = set()\n",
    "            used_col_indices = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_row_indices or col in used_col_indices:\n",
    "                    continue\n",
    "\n",
    "                if distances[row, col] > self.max_distance:\n",
    "                    continue\n",
    "\n",
    "                # Update existing object\n",
    "                object_id = object_ids[row]\n",
    "                self.objects[object_id]['centroid'] = input_centroids[col]\n",
    "                self.objects[object_id]['detection'] = detections[col]\n",
    "                self.objects[object_id]['trajectory'].append(input_centroids[col])\n",
    "                self.objects[object_id]['frame_count'] += 1\n",
    "                self.disappeared[object_id] = 0\n",
    "\n",
    "                used_row_indices.add(row)\n",
    "                used_col_indices.add(col)\n",
    "\n",
    "            # Handle unmatched detections and objects\n",
    "            unused_rows = set(range(0, distances.shape[0])).difference(used_row_indices)\n",
    "            unused_cols = set(range(0, distances.shape[1])).difference(used_col_indices)\n",
    "\n",
    "            if distances.shape[0] >= distances.shape[1]:\n",
    "                # More objects than detections\n",
    "                for row in unused_rows:\n",
    "                    object_id = object_ids[row]\n",
    "                    self.disappeared[object_id] += 1\n",
    "                    if self.disappeared[object_id] > self.max_disappeared:\n",
    "                        self.deregister(object_id)\n",
    "            else:\n",
    "                # More detections than objects\n",
    "                for col in unused_cols:\n",
    "                    self.register(input_centroids[col], detections[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "def visualize_tracking(frame, tracked_objects):\n",
    "    \"\"\"Visualize tracking results\"\"\"\n",
    "    vis_frame = frame.copy()\n",
    "\n",
    "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "              (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)]\n",
    "\n",
    "    for i, (object_id, obj_info) in enumerate(tracked_objects.items()):\n",
    "        centroid = obj_info['centroid']\n",
    "        trajectory = obj_info['trajectory']\n",
    "        detection = obj_info['detection']\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Draw bounding box\n",
    "        bbox = detection['bbox']\n",
    "        cv2.rectangle(vis_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "\n",
    "        # Draw trajectory\n",
    "        if len(trajectory) > 1:\n",
    "            for j in range(1, len(trajectory)):\n",
    "                cv2.line(vis_frame, trajectory[j-1], trajectory[j], color, 2)\n",
    "\n",
    "        # Draw centroid\n",
    "        cv2.circle(vis_frame, centroid, 5, color, -1)\n",
    "\n",
    "        # Draw ID\n",
    "        cv2.putText(vis_frame, f\"ID: {object_id}\",\n",
    "                   (centroid[0] - 20, centroid[1] - 20),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Draw vehicle type\n",
    "        vehicle_type = detection.get('enhanced_class', detection.get('class', 'unknown'))\n",
    "        cv2.putText(vis_frame, vehicle_type,\n",
    "                   (bbox[0], bbox[1] - 5),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    return vis_frame\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = SimpleVehicleTracker(max_disappeared=5, max_distance=80)\n",
    "\n",
    "# Simulate tracking across multiple frames\n",
    "print(\"\\nðŸŽ¬ Simulating vehicle tracking across frames...\")\n",
    "\n",
    "if sample_frames:\n",
    "    # Create multiple frames with slight variations to simulate movement\n",
    "    tracking_frames = []\n",
    "    tracking_results = []\n",
    "\n",
    "    base_detections = process_frame_with_classification(sample_frames[0], model)\n",
    "\n",
    "    # Simulate movement across 5 frames\n",
    "    for frame_idx in range(5):\n",
    "        # Simulate vehicle movement\n",
    "        simulated_detections = []\n",
    "        for det in base_detections:\n",
    "            bbox = det['bbox'].copy()\n",
    "\n",
    "            # Simulate movement (move vehicles slightly)\n",
    "            movement_x = frame_idx * 10 + np.random.randint(-5, 5)\n",
    "            movement_y = np.random.randint(-2, 2)\n",
    "\n",
    "            bbox[0] += movement_x\n",
    "            bbox[2] += movement_x\n",
    "            bbox[1] += movement_y\n",
    "            bbox[3] += movement_y\n",
    "\n",
    "            # Keep bbox within frame\n",
    "            bbox[0] = max(0, bbox[0])\n",
    "            bbox[2] = min(sample_frames[0].shape[1], bbox[2])\n",
    "            bbox[1] = max(0, bbox[1])\n",
    "            bbox[3] = min(sample_frames[0].shape[0], bbox[3])\n",
    "\n",
    "            sim_det = det.copy()\n",
    "            sim_det['bbox'] = bbox\n",
    "            simulated_detections.append(sim_det)\n",
    "\n",
    "        # Update tracker\n",
    "        tracked_objects = tracker.update(simulated_detections)\n",
    "        tracking_results.append(tracked_objects.copy())\n",
    "\n",
    "        # Create visualization frame\n",
    "        vis_frame = visualize_tracking(sample_frames[0], tracked_objects)\n",
    "        tracking_frames.append(vis_frame)\n",
    "\n",
    "    # Display tracking results\n",
    "    fig, axes = plt.subplots(1, len(tracking_frames), figsize=(20, 4))\n",
    "    if len(tracking_frames) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (frame, ax) in enumerate(zip(tracking_frames, axes)):\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(f'Frame {i+1}\\\\nTracked Objects: {len(tracking_results[i])}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Vehicle Tracking Across Frames')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Tracking statistics\n",
    "    print(f\"\\\\nðŸ“Š Tracking Statistics:\")\n",
    "    print(f\"   Total objects tracked: {tracker.next_object_id}\")\n",
    "    print(f\"   Currently active objects: {len(tracker.objects)}\")\n",
    "\n",
    "    # Trajectory analysis\n",
    "    for obj_id, obj_info in tracker.objects.items():\n",
    "        trajectory = obj_info['trajectory']\n",
    "        if len(trajectory) > 1:\n",
    "            distance_traveled = sum([\n",
    "                np.sqrt((trajectory[i][0] - trajectory[i-1][0])**2 +\n",
    "                       (trajectory[i][1] - trajectory[i-1][1])**2)\n",
    "                for i in range(1, len(trajectory))\n",
    "            ])\n",
    "            print(f\"   Object {obj_id}: {len(trajectory)} points, {distance_traveled:.1f}px traveled\")\n",
    "\n",
    "print(\"\\\\nâœ… Vehicle tracking implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d16f88",
   "metadata": {},
   "source": [
    "## 6. Count Vehicles by Type\n",
    "\n",
    "Count the number of each vehicle type passing through defined zones or crossing lines in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ab0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle counting system\n",
    "print(\"ðŸ”¢ Implementing vehicle counting system...\")\n",
    "\n",
    "class VehicleCounter:\n",
    "    \"\"\"Vehicle counter with line crossing detection\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_counts = defaultdict(int)\n",
    "        self.crossed_objects = set()\n",
    "        self.counting_line = None\n",
    "\n",
    "    def set_counting_line(self, line_points):\n",
    "        \"\"\"Set the counting line\"\"\"\n",
    "        self.counting_line = line_points\n",
    "\n",
    "    def check_line_crossing(self, object_id, current_pos, previous_pos):\n",
    "        \"\"\"Check if object crossed the counting line\"\"\"\n",
    "        if self.counting_line is None or previous_pos is None:\n",
    "            return False\n",
    "\n",
    "        x1, y1 = self.counting_line\n",
    "        x2, y2 = current_pos\n",
    "        x0, y0 = previous_pos\n",
    "\n",
    "        # Simple crossing detection (check if crossed horizontal line)\n",
    "        if y0 < y1 and y2 >= y1:\n",
    "            return True\n",
    "        elif y0 > y1 and y2 <= y1:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def update(self, tracked_objects):\n",
    "        \"\"\"Update counts based on tracked objects\"\"\"\n",
    "        for obj_id, obj_info in tracked_objects.items():\n",
    "            trajectory = obj_info['trajectory']\n",
    "            vehicle_type = obj_info['detection'].get('enhanced_class', obj_info['detection'].get('class'))\n",
    "\n",
    "            # Check if crossed counting line\n",
    "            if len(trajectory) >= 2 and obj_id not in self.crossed_objects:\n",
    "                if self.check_line_crossing(obj_id, trajectory[-1], trajectory[-2]):\n",
    "                    self.total_counts[vehicle_type] += 1\n",
    "                    self.total_counts['total'] += 1\n",
    "                    self.crossed_objects.add(obj_id)\n",
    "\n",
    "        return self.total_counts\n",
    "\n",
    "def visualize_counts(frame, counts, counting_line=None):\n",
    "    \"\"\"Visualize vehicle counts\"\"\"\n",
    "    vis_frame = frame.copy()\n",
    "\n",
    "    # Draw counting line if specified\n",
    "    if counting_line:\n",
    "        y_line = counting_line[1]\n",
    "        cv2.line(vis_frame, (0, y_line), (vis_frame.shape[1], y_line), (0, 255, 255), 3)\n",
    "        cv2.putText(vis_frame, \"Counting Line\", (10, y_line - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Draw count information\n",
    "    y_offset = 30\n",
    "    cv2.rectangle(vis_frame, (10, 10), (300, 30 + len(counts) * 30), (0, 0, 0), -1)\n",
    "    cv2.rectangle(vis_frame, (10, 10), (300, 30 + len(counts) * 30), (255, 255, 255), 2)\n",
    "\n",
    "    cv2.putText(vis_frame, \"Vehicle Counts\", (20, y_offset),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    y_offset += 30\n",
    "    for vehicle_type, count in sorted(counts.items()):\n",
    "        text = f\"{vehicle_type.capitalize()}: {count}\"\n",
    "        cv2.putText(vis_frame, text, (20, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        y_offset += 25\n",
    "\n",
    "    return vis_frame\n",
    "\n",
    "# Initialize counter\n",
    "counter = VehicleCounter()\n",
    "\n",
    "# Set counting line (middle of frame)\n",
    "if sample_frames:\n",
    "    counting_line_y = sample_frames[0].shape[0] // 2\n",
    "    counter.set_counting_line((0, counting_line_y))\n",
    "\n",
    "    print(f\"\\\\nðŸ“ Counting line set at y={counting_line_y}\")\n",
    "\n",
    "    # Simulate counting across tracking results\n",
    "    print(\"\\\\nðŸ”¢ Counting vehicles...\")\n",
    "\n",
    "    count_frames = []\n",
    "    for i, tracked_obj in enumerate(tracking_results):\n",
    "        counts = counter.update(tracked_obj)\n",
    "        vis_frame = visualize_counts(tracking_frames[i], counts, (0, counting_line_y))\n",
    "        count_frames.append(vis_frame)\n",
    "\n",
    "    # Display counting results\n",
    "    fig, axes = plt.subplots(1, len(count_frames), figsize=(20, 4))\n",
    "    if len(count_frames) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (frame, ax) in enumerate(zip(count_frames, axes)):\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(f'Frame {i+1}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Vehicle Counting Across Frames')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Final count summary\n",
    "    print(f\"\\\\nðŸ“Š Final Vehicle Counts:\")\n",
    "    final_counts = counter.total_counts\n",
    "    for vehicle_type, count in sorted(final_counts.items()):\n",
    "        print(f\"   {vehicle_type.capitalize()}: {count}\")\n",
    "\n",
    "    # Visualize count distribution\n",
    "    if len(final_counts) > 1:\n",
    "        # Remove 'total' for pie chart\n",
    "        count_dict = {k: v for k, v in final_counts.items() if k != 'total'}\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        # Pie chart\n",
    "        ax1.pie(count_dict.values(), labels=count_dict.keys(), autopct='%1.1f%%',\n",
    "               startangle=90, colors=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "        ax1.set_title('Vehicle Type Distribution')\n",
    "\n",
    "        # Bar chart\n",
    "        ax2.bar(count_dict.keys(), count_dict.values(), color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "        ax2.set_title('Vehicle Counts by Type')\n",
    "        ax2.set_xlabel('Vehicle Type')\n",
    "        ax2.set_ylabel('Count')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\\\nâœ… Vehicle counting system complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246e87b",
   "metadata": {},
   "source": [
    "## 7. Calculate Traffic Flow Metrics & Estimate Congestion Levels\n",
    "\n",
    "Compute traffic flow statistics and classify traffic conditions as light, moderate, or heavy congestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7705254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic flow metrics and congestion analysis\n",
    "print(\"ðŸ“ˆ Analyzing traffic flow and estimating congestion levels...\")\n",
    "\n",
    "class CongestionAnalyzer:\n",
    "    \"\"\"Analyze traffic congestion levels\"\"\"\n",
    "\n",
    "    def __init__(self, thresholds={'low': 5, 'medium': 10, 'high': 15}):\n",
    "        self.thresholds = thresholds\n",
    "        self.flow_history = []\n",
    "\n",
    "    def calculate_congestion_level(self, vehicle_count, frame_area):\n",
    "        \"\"\"Calculate congestion level based on vehicle density\"\"\"\n",
    "        density = (vehicle_count * 10000) / frame_area  # Normalize by area\n",
    "\n",
    "        if density <= self.thresholds['low']:\n",
    "            return 'Low', 'green', density\n",
    "        elif density <= self.thresholds['medium']:\n",
    "            return 'Medium', 'yellow', density\n",
    "        else:\n",
    "            return 'High', 'red', density\n",
    "\n",
    "    def calculate_flow_rate(self, vehicles_per_time_window, time_window_seconds):\n",
    "        \"\"\"Calculate vehicles per minute\"\"\"\n",
    "        if time_window_seconds > 0:\n",
    "            return (vehicles_per_time_window / time_window_seconds) * 60\n",
    "        return 0\n",
    "\n",
    "    def calculate_average_speed(self, tracked_objects):\n",
    "        \"\"\"Calculate average vehicle speed\"\"\"\n",
    "        speeds = []\n",
    "        for obj_id, obj_info in tracked_objects.items():\n",
    "            trajectory = obj_info['trajectory']\n",
    "            if len(trajectory) >= 2:\n",
    "                p1, p2 = trajectory[-2], trajectory[-1]\n",
    "                speed = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "                speeds.append(speed)\n",
    "\n",
    "        return np.mean(speeds) if speeds else 0\n",
    "\n",
    "    def analyze_traffic(self, tracked_objects, frame_shape):\n",
    "        \"\"\"Comprehensive traffic analysis\"\"\"\n",
    "        frame_area = frame_shape[0] * frame_shape[1]\n",
    "        vehicle_count = len(tracked_objects)\n",
    "\n",
    "        # Congestion level\n",
    "        congestion_level, congestion_color, density = self.calculate_congestion_level(\n",
    "            vehicle_count, frame_area\n",
    "        )\n",
    "\n",
    "        # Average speed\n",
    "        avg_speed = self.calculate_average_speed(tracked_objects)\n",
    "\n",
    "        # Vehicle type breakdown\n",
    "        type_counts = defaultdict(int)\n",
    "        for obj_info in tracked_objects.values():\n",
    "            vehicle_type = obj_info['detection'].get('enhanced_class',\n",
    "                                                     obj_info['detection'].get('class'))\n",
    "            type_counts[vehicle_type] += 1\n",
    "\n",
    "        analysis = {\n",
    "            'vehicle_count': vehicle_count,\n",
    "            'congestion_level': congestion_level,\n",
    "            'congestion_color': congestion_color,\n",
    "            'traffic_density': density,\n",
    "            'average_speed': avg_speed,\n",
    "            'vehicle_breakdown': dict(type_counts),\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "\n",
    "        self.flow_history.append(analysis)\n",
    "        return analysis\n",
    "\n",
    "def visualize_congestion(frame, analysis):\n",
    "    \"\"\"Visualize congestion information\"\"\"\n",
    "    vis_frame = frame.copy()\n",
    "\n",
    "    # Draw congestion indicator\n",
    "    congestion_level = analysis['congestion_level']\n",
    "    congestion_color_name = analysis['congestion_color']\n",
    "\n",
    "    color_map = {\n",
    "        'green': (0, 255, 0),\n",
    "        'yellow': (0, 255, 255),\n",
    "        'red': (0, 0, 255)\n",
    "    }\n",
    "    color = color_map.get(congestion_color_name, (255, 255, 255))\n",
    "\n",
    "    # Draw congestion indicator circle\n",
    "    cv2.circle(vis_frame, (vis_frame.shape[1] - 50, 50), 30, color, -1)\n",
    "    cv2.circle(vis_frame, (vis_frame.shape[1] - 50, 50), 30, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw info panel\n",
    "    panel_height = 150\n",
    "    cv2.rectangle(vis_frame, (10, 10), (350, panel_height), (0, 0, 0), -1)\n",
    "    cv2.rectangle(vis_frame, (10, 10), (350, panel_height), (255, 255, 255), 2)\n",
    "\n",
    "    # Add text information\n",
    "    info_text = [\n",
    "        f\"Congestion Level: {congestion_level}\",\n",
    "        f\"Vehicles: {analysis['vehicle_count']}\",\n",
    "        f\"Density: {analysis['traffic_density']:.2f}\",\n",
    "        f\"Avg Speed: {analysis['average_speed']:.1f} px/frame\",\n",
    "    ]\n",
    "\n",
    "    y_pos = 35\n",
    "    for text in info_text:\n",
    "        cv2.putText(vis_frame, text, (20, y_pos),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        y_pos += 30\n",
    "\n",
    "    return vis_frame\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = CongestionAnalyzer(thresholds={'low': 2, 'medium': 4, 'high': 6})\n",
    "\n",
    "if sample_frames and tracking_results:\n",
    "    print(\"\\\\nðŸš¦ Analyzing traffic congestion...\")\n",
    "\n",
    "    # Analyze each frame\n",
    "    congestion_frames = []\n",
    "    congestion_analyses = []\n",
    "\n",
    "    for i, tracked_obj in enumerate(tracking_results):\n",
    "        analysis = analyzer.analyze_traffic(tracked_obj, sample_frames[0].shape)\n",
    "        congestion_analyses.append(analysis)\n",
    "\n",
    "        vis_frame = visualize_congestion(tracking_frames[i], analysis)\n",
    "        congestion_frames.append(vis_frame)\n",
    "\n",
    "    # Display congestion analysis\n",
    "    fig, axes = plt.subplots(1, len(congestion_frames), figsize=(20, 4))\n",
    "    if len(congestion_frames) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (frame, ax, analysis) in enumerate(zip(congestion_frames, axes, congestion_analyses)):\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(f'Frame {i+1}\\\\nCongestion: {analysis[\"congestion_level\"]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Traffic Congestion Analysis')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Traffic flow metrics over time\n",
    "    print(\"\\\\nðŸ“Š Traffic Flow Metrics:\")\n",
    "\n",
    "    df_flow = pd.DataFrame([{\n",
    "        'Frame': i+1,\n",
    "        'Vehicles': analysis['vehicle_count'],\n",
    "        'Congestion': analysis['congestion_level'],\n",
    "        'Density': analysis['traffic_density'],\n",
    "        'Speed': analysis['average_speed']\n",
    "    } for i, analysis in enumerate(congestion_analyses)])\n",
    "\n",
    "    print(df_flow.to_string(index=False))\n",
    "\n",
    "    # Visualize metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Vehicle count over time\n",
    "    axes[0, 0].plot(df_flow['Frame'], df_flow['Vehicles'], marker='o', linewidth=2, color='blue')\n",
    "    axes[0, 0].set_title('Vehicle Count Over Time')\n",
    "    axes[0, 0].set_xlabel('Frame')\n",
    "    axes[0, 0].set_ylabel('Number of Vehicles')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Traffic density\n",
    "    axes[0, 1].plot(df_flow['Frame'], df_flow['Density'], marker='s', linewidth=2, color='orange')\n",
    "    axes[0, 1].set_title('Traffic Density Over Time')\n",
    "    axes[0, 1].set_xlabel('Frame')\n",
    "    axes[0, 1].set_ylabel('Density')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Average speed\n",
    "    axes[1, 0].plot(df_flow['Frame'], df_flow['Speed'], marker='^', linewidth=2, color='green')\n",
    "    axes[1, 0].set_title('Average Speed Over Time')\n",
    "    axes[1, 0].set_xlabel('Frame')\n",
    "    axes[1, 0].set_ylabel('Speed (px/frame)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Congestion level distribution\n",
    "    congestion_dist = df_flow['Congestion'].value_counts()\n",
    "    colors = ['green' if level == 'Low' else 'yellow' if level == 'Medium' else 'red'\n",
    "             for level in congestion_dist.index]\n",
    "    axes[1, 1].bar(congestion_dist.index, congestion_dist.values, color=colors, alpha=0.7)\n",
    "    axes[1, 1].set_title('Congestion Level Distribution')\n",
    "    axes[1, 1].set_xlabel('Congestion Level')\n",
    "    axes[1, 1].set_ylabel('Number of Frames')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\\\nðŸ“ˆ Summary Statistics:\")\n",
    "    print(f\"   Average vehicles per frame: {df_flow['Vehicles'].mean():.1f}\")\n",
    "    print(f\"   Peak vehicle count: {df_flow['Vehicles'].max()}\")\n",
    "    print(f\"   Average traffic density: {df_flow['Density'].mean():.2f}\")\n",
    "    print(f\"   Average speed: {df_flow['Speed'].mean():.2f} px/frame\")\n",
    "    print(f\"   Most common congestion level: {df_flow['Congestion'].mode()[0]}\")\n",
    "\n",
    "print(\"\\\\nâœ… Traffic flow and congestion analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dd3312",
   "metadata": {},
   "source": [
    "## 8. Advanced Visualizations and Dashboard\n",
    "\n",
    "Create comprehensive visualizations including heatmaps, interactive dashboards, and analytics reports for smart city applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced visualizations and interactive dashboard\n",
    "print(\"ðŸ“Š Creating advanced visualizations and interactive dashboard...\")\n",
    "\n",
    "# Create trajectory heatmap\n",
    "def create_trajectory_heatmap(tracked_objects, frame_shape):\n",
    "    \"\"\"Create heatmap from vehicle trajectories\"\"\"\n",
    "    heatmap = np.zeros((frame_shape[0], frame_shape[1]), dtype=np.float32)\n",
    "\n",
    "    for obj_id, obj_info in tracked_objects.items():\n",
    "        trajectory = obj_info['trajectory']\n",
    "        for x, y in trajectory:\n",
    "            if 0 <= x < frame_shape[1] and 0 <= y < frame_shape[0]:\n",
    "                # Add Gaussian blob around each point\n",
    "                y_min, y_max = max(0, y-10), min(frame_shape[0], y+10)\n",
    "                x_min, x_max = max(0, x-10), min(frame_shape[1], x+10)\n",
    "                heatmap[y_min:y_max, x_min:x_max] += 1\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (15, 15), 0)\n",
    "\n",
    "    # Normalize\n",
    "    if heatmap.max() > 0:\n",
    "        heatmap = (heatmap / heatmap.max() * 255).astype(np.uint8)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "if sample_frames and tracking_results:\n",
    "    # Combine all tracked objects for heatmap\n",
    "    all_tracked = {}\n",
    "    for tracked in tracking_results:\n",
    "        for obj_id, obj_info in tracked.items():\n",
    "            if obj_id not in all_tracked:\n",
    "                all_tracked[obj_id] = obj_info\n",
    "            else:\n",
    "                # Extend trajectory\n",
    "                all_tracked[obj_id]['trajectory'].extend(obj_info['trajectory'])\n",
    "\n",
    "    # Create heatmap\n",
    "    print(\"\\\\nðŸ—ºï¸ Creating traffic density heatmap...\")\n",
    "    heatmap = create_trajectory_heatmap(all_tracked, sample_frames[0].shape)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Overlay on frame\n",
    "    overlay = cv2.addWeighted(sample_frames[0], 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    axes[0].imshow(cv2.cvtColor(sample_frames[0], cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Frame')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(heatmap, cmap='hot')\n",
    "    axes[1].set_title('Traffic Density Heatmap')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    axes[2].set_title('Heatmap Overlay')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.suptitle('Traffic Density Visualization')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive dashboard with Plotly\n",
    "if congestion_analyses:\n",
    "    print(\"\\\\nðŸ“ˆ Creating interactive dashboard...\")\n",
    "\n",
    "    # Prepare data\n",
    "    df_dashboard = pd.DataFrame([{\n",
    "        'Frame': i+1,\n",
    "        'Vehicles': analysis['vehicle_count'],\n",
    "        'Congestion_Level': analysis['congestion_level'],\n",
    "        'Density': analysis['traffic_density'],\n",
    "        'Speed': analysis['average_speed'],\n",
    "        'Time': i * 1  # seconds\n",
    "    } for i, analysis in enumerate(congestion_analyses)])\n",
    "\n",
    "    # Create interactive subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Vehicle Count Timeline', 'Congestion Distribution',\n",
    "                       'Traffic Density vs Speed', 'Vehicle Type Breakdown'),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'bar'}],\n",
    "               [{'type': 'scatter'}, {'type': 'pie'}]]\n",
    "    )\n",
    "\n",
    "    # Vehicle count timeline\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_dashboard['Frame'], y=df_dashboard['Vehicles'],\n",
    "                  mode='lines+markers', name='Vehicle Count',\n",
    "                  line=dict(color='blue', width=3),\n",
    "                  marker=dict(size=8)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Congestion distribution\n",
    "    congestion_counts = df_dashboard['Congestion_Level'].value_counts()\n",
    "    colors_cong = ['green' if level == 'Low' else 'yellow' if level == 'Medium' else 'red'\n",
    "                   for level in congestion_counts.index]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=congestion_counts.index, y=congestion_counts.values,\n",
    "               marker_color=colors_cong, name='Congestion'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Density vs Speed scatter\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_dashboard['Density'], y=df_dashboard['Speed'],\n",
    "                  mode='markers', name='Density vs Speed',\n",
    "                  marker=dict(size=12, color=df_dashboard['Vehicles'],\n",
    "                            colorscale='Viridis', showscale=True)),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Vehicle type breakdown (if available)\n",
    "    if counter.total_counts:\n",
    "        count_dict = {k: v for k, v in counter.total_counts.items() if k != 'total'}\n",
    "        fig.add_trace(\n",
    "            go.Pie(labels=list(count_dict.keys()), values=list(count_dict.values()),\n",
    "                  name='Vehicle Types'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        title_text=\"Traffic Flow Analysis Dashboard\",\n",
    "        title_font_size=20\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Generate comprehensive report\n",
    "print(\"\\\\nðŸ“ Generating Comprehensive Analysis Report...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "report = f\"\"\"\n",
    "TRAFFIC FLOW ANALYSIS REPORT\n",
    "{'='*70}\n",
    "\n",
    "ANALYSIS OVERVIEW:\n",
    "- Total Frames Analyzed: {len(congestion_analyses) if congestion_analyses else 0}\n",
    "- Analysis Duration: {len(congestion_analyses)} frames\n",
    "- Frame Size: {sample_frames[0].shape if sample_frames else 'N/A'}\n",
    "\n",
    "VEHICLE DETECTION & CLASSIFICATION:\n",
    "- Total Objects Tracked: {tracker.next_object_id if tracker else 0}\n",
    "- Currently Active Objects: {len(tracker.objects) if tracker else 0}\n",
    "\n",
    "VEHICLE COUNT SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "if counter.total_counts:\n",
    "    for vehicle_type, count in sorted(counter.total_counts.items()):\n",
    "        report += f\"- {vehicle_type.capitalize()}: {count}\\\\n\"\n",
    "\n",
    "if df_flow is not None:\n",
    "    report += f\"\"\"\n",
    "TRAFFIC METRICS:\n",
    "- Average Vehicles per Frame: {df_flow['Vehicles'].mean():.2f}\n",
    "- Peak Vehicle Count: {df_flow['Vehicles'].max()}\n",
    "- Minimum Vehicle Count: {df_flow['Vehicles'].min()}\n",
    "- Average Traffic Density: {df_flow['Density'].mean():.2f}\n",
    "- Average Vehicle Speed: {df_flow['Speed'].mean():.2f} pixels/frame\n",
    "\n",
    "CONGESTION ANALYSIS:\n",
    "- Low Congestion Frames: {(df_flow['Congestion'] == 'Low').sum()}\n",
    "- Medium Congestion Frames: {(df_flow['Congestion'] == 'Medium').sum()}\n",
    "- High Congestion Frames: {(df_flow['Congestion'] == 'High').sum()}\n",
    "- Predominant Congestion Level: {df_flow['Congestion'].mode()[0]}\n",
    "\n",
    "SMART CITY INSIGHTS:\n",
    "- Traffic Pattern: {'Stable' if df_flow['Vehicles'].std() < 2 else 'Variable'}\n",
    "- Recommended Action: {'Monitor' if (df_flow['Congestion'] == 'High').sum() == 0 else 'Intervention Needed'}\n",
    "- Flow Efficiency: {'Good' if df_flow['Speed'].mean() > 5 else 'Poor'}\n",
    "\"\"\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'='*70}\n",
    "Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "System: Traffic Flow Analysis Using CCTV Footage\n",
    "Version: 1.0\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file (optional)\n",
    "# with open('../output/analytics/traffic_report.txt', 'w') as f:\n",
    "#     f.write(report)\n",
    "\n",
    "print(\"\\\\nâœ… All analyses and visualizations complete!\")\n",
    "print(\"\\\\nðŸŽ‰ Traffic Flow Analysis Demo Successfully Completed!\")\n",
    "print(\"\\\\nThis system can be applied to:\")\n",
    "print(\"  â€¢ Smart city traffic management\")\n",
    "print(\"  â€¢ Congestion monitoring and prediction\")\n",
    "print(\"  â€¢ Traffic pattern analysis\")\n",
    "print(\"  â€¢ Urban planning and infrastructure optimization\")\n",
    "print(\"  â€¢ Incident detection and response\")\n",
    "print(\"  â€¢ Environmental impact assessment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
